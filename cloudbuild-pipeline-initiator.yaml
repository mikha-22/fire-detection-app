# fire-detection-app/cloudbuild-pipeline-initiator.yaml
steps:
# Step 1: Create a staging directory for the function
- name: 'gcr.io/cloud-builders/gcloud'
  entrypoint: 'bash'
  args:
  - '-c'
  - |
    mkdir -p deploy_staging/pipeline_initiator
    cp src/cloud_functions/pipeline_initiator/main.py deploy_staging/pipeline_initiator/main.py
    cp src/cloud_functions/pipeline_initiator/requirements.txt deploy_staging/pipeline_initiator/requirements.txt
    # Copy the entire shared 'src' directory into the staging area for this function
    # This makes 'from src.common...' imports work.
    cp -r src deploy_staging/pipeline_initiator/src

# Step 2: Deploy the function from the staging directory
- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk' # Official Cloud SDK image
  entrypoint: 'gcloud'
  args:
  - 'functions'
  - 'deploy'
  - 'PipelineInitiatorCF'
  - '--gen2'
  - '--runtime=python311'
  - '--region=asia-southeast2'
  - '--source=./deploy_staging/pipeline_initiator' # Source is now the prepared staging dir
  - '--entry-point=pipeline_initiator_cloud_function'
  - '--trigger-topic=wildfire-pipeline-initiator'
  - '--service-account=fire-app-vm-service-account@haryo-kebakaran.iam.gserviceaccount.com'
  - '--set-env-vars=GCP_PROJECT_ID=haryo-kebakaran,GCP_REGION=asia-southeast2,FIRMS_API_KEY=0331973a7ee830ca7f026493faaa367a,VERTEX_AI_MODEL_NAME=dummy_wildfire_detector_v1,VERTEX_NOTIFICATION_PUBSUB_TOPIC_NAME=vertex-job-completion-topic'
  - '--timeout=540s'
  - '--memory=1GiB'  # <--- INCREASED MEMORY
  - '--project=haryo-kebakaran'

options:
  logging: CLOUD_LOGGING_ONLY
  # machineType: 'E2_MEDIUM' # Optional: specify machine type for the build itself
timeout: '1200s' # Timeout for the entire Cloud Build job (all steps)

