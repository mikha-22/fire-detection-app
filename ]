# src/ml_model/predictor.py

import os
import json
import numpy as np
from typing import Any, Dict, List

from google.cloud.aiplatform.prediction.predictor import Predictor

# --- Heuristic Model Logic (self-contained within the predictor file) ---
# This class is a direct implementation of the logic from the framework document.

class FireRiskHeuristicModel:
    def __init__(self, config: Dict[str, Any]):
        if 'criteria' not in config or not isinstance(config['criteria'], list):
            raise ValueError("Configuration must contain a 'criteria' list.")
        self.criteria: List[Dict[str, Any]] = config['criteria']
        self._validate_config()

    def _validate_config(self):
        total_weight = sum(c['weight'] for c in self.criteria)
        if not np.isclose(total_weight, 1.0):
            raise ValueError(f"Sum of all weights must be 1.0, but is {total_weight}")

    def _sigmoid(self, x: float) -> float:
        return 1 / (1 + np.exp(-x))

    def _get_value_from_dot_key(self, data: Dict[str, Any], key: str) -> Any:
        keys = key.split('.')
        value = data
        for k in keys:
            if isinstance(value, dict) and k in value:
                value = value[k]
            else: return None
        return value

    def _get_criterion_score(self, criterion: Dict[str, Any], data: Dict[str, Any]) -> float:
        value = self._get_value_from_dot_key(data, criterion['data_key'])
        if value is None: return 5.0

        if criterion['type'] == 'categorical':
            return float(criterion['mapping'].get(str(value).lower(), 5.0))
        elif criterion['type'] == 'numerical_threshold':
            for threshold, score in sorted(criterion['mapping'].items(), key=lambda i: float(i[0])):
                if float(value) <= float(threshold): return float(score)
            return float(min(criterion['mapping'].values()))
        raise ValueError(f"Unsupported criterion type: {criterion['type']}")

    def _calculate_raw_score(self, data: Dict[str, Any]) -> float:
        total_raw_score = sum(self._get_criterion_score(c, data) * c['weight'] for c in self.criteria)
        return total_raw_score - 5.0

    def predict_confidence(self, data: Dict[str, Any]) -> Dict[str, Any]:
        raw_score = self._calculate_raw_score(data)
        confidence_score = self._sigmoid(raw_score)
        return {"confidence_score": confidence_score, "raw_score": raw_score}

# --- CPR Predictor Class ---
# This is the wrapper that Vertex AI interacts with.

class WildfireHeuristicPredictor(Predictor):
    def __init__(self):
        self._model = None

    def load(self, artifacts_uri: str) -> None:
        """
        Loads the heuristic model configuration.
        `artifacts_uri` is a GCS path to the directory where the model artifacts are stored.
        For CPR, this directory is automatically created from the files in the build context.
        """
        config_path = os.path.join(artifacts_uri, "config.json")
        if not os.path.exists(config_path):
             # Fallback for local testing where artifacts_uri might be the script's directory
             config_path = "config.json"

        with open(config_path, 'r') as f:
            model_config = json.load(f)
        
        self._model = FireRiskHeuristicModel(config=model_config)

    def preprocess(self, prediction_input: Dict[str, Any]) -> Dict[str, Any]:
        """
        Pass-through preprocessing. The input JSONL from the batch job
        is expected to be in the correct format already.
        """
        return prediction_input

    def predict(self, instances: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Runs the heuristic model on each instance.
        """
        predictions = []
        for instance in instances:
            # The instance itself is the data we need
            cluster_id = instance.get("cluster_id", "unknown_instance")
            result = self._model.predict_confidence(instance)
            
            # Add the instance_id to the result for Vertex AI to track
            result["instance_id"] = cluster_id
            predictions.append(result)
            
        return predictions

    def postprocess(self, prediction_results: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """
        Formats the predictions into the structure required by Vertex AI Batch Prediction.
        """
        return {"predictions": prediction_results}
